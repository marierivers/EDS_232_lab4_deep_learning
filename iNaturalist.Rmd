---
title: "iNaturalist Lab"
author: "Marie Rivers"
date: "2/22/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
librarian::shelf(
  digest, dplyr, DT, glue, purrr, readr, stringr, tidyr)
```

Apply deep learning and convnet techniques to a small subset of iNaturalist species imagery. These data were downloaded from the links provided at [github.com/visipedia/inat_comp:2021/](https://github.com/visipedia/inat_comp/tree/master/2021). This lab only draws from the Train Mini set of images.

The first step is to move the images into directories for the variety of models. The `keras::flow_images_from_firectory()` expects the first argument `directory` to contain one subdirectory per class. Since we are building models for two species `spp2` (binary) and ten species `spp10` (multiclass), plus we want to have `train` (n=30) and `test` (n=10) images assigned to each, we want an appropriate directory structure.

```{r}
librarian::shelf(digest, dplyr, DT, glue, purrr, readr, stringr, tidyr)
```

```{r}
# path to folder containing species directories of images
dir_src <- "/courses/EDS232/inaturalist-2021/train_mini"
dir_dest <- "~/inat"
dir.create(dir_dest, showWarnings = F)

# get list of directories, one per species (n = 10,000 species)
dirs_spp <- list.dirs(dir_src, recursive = F, full.names = T)
n_spp <- length(dirs_spp)
```

```{r}
# set seed for reproducible results just before sampling otherwise you'll get different results, based on your username
Sys.info()[["user"]] %>% 
  digest::digest2int() %>% 
  set.seed()
i10 <- sample(1:n_spp, 10)

# show the 10 indices sampled of the 10,000 possible
i10
```

```{r}
# show the 10 species directory names
basename(dirs_spp)[i10]
```
```{r}
# show the first 2 species directory names
i2 <- i10[1:2]
basename(dirs_spp)[i2]
```
# Split the original images per species (n=50) into train (n=30), validate (n=10) and test (n=10)
```{r}
# setup data frame with source (src) and destination (dest) paths to images
d <- tibble(
  set = c(rep("spp2", 2), rep("spp10", 10)),
  dir_sp = c(dirs_spp[i2], dirs_spp[i10]),
  tbl_img = map(dir_sp, function(dir_sp){
    tibble(
      src_img = list.files(dir_sp, full.names = T),
      subset = c(rep("train", 30), rep("validation", 10), rep("test", 10))) })) %>% 
  unnest(tbl_img) %>% 
  mutate(
    sp = basename(dir_sp),
    img = basename(src_img),
    dest_img = glue("{dir_dest}/{set}/{subset}/{sp}/{img}"))
```

```{r}
# show source and destination for first 10 rows of tibble
d %>% 
  select(src_img, dest_img)
```

```{r}
# iterage over rows, creating directory if needed and copying files
d %>% 
  pwalk(function(src_img, dest_img, ...){
    dir.create(dirname(dest_img), recursive = T, showWarnings = F)
    file.copy(src_img, dest_img) })
```

```{r}
# uncomment to show the entire tree of your destination directory
# system(glue("tree {dir_dest}"))
```

# 2 Species (binary classification) - neural net

## accuracy metric and validation in the fitting process

## history plot.

## Evaluate loss and accuracy on  test model results. 

## Compare standard neural network and convolutional neural network results

# 2 Species (binary classification) - convolutional neural net

## accuracy metric and validation in the fitting process

## history plot.

## Evaluate loss and accuracy on  test model results. 

## Compare standard neural network and convolutional neural network results

# 10 Species (multi-class classification) - neural net

## accuracy metric and validation in the fitting process

## history plot.

## Evaluate loss and accuracy on  test model results. 

## Compare standard neural network and convolutional neural network results

# 10 Species (multi-class classification) - neural net

## accuracy metric and validation in the fitting process

## history plot.

## Evaluate loss and accuracy on  test model results. 

## Compare standard neural network and convolutional neural network results

Your task is to apply your deep learning skills to build the following models:

1. **2 Species (binary classification) - neural net**. Draw from [3.4 üçø Movies (binary classification)](./lab4b_examples.html). You'll need to pre-process the images to be a consistent shape first though -- see 5.2.4 Data preprocessing.

1. **2 Species (binary classification) - convolutional neural net**. Draw from the [dogs vs cats example](https://bbest.github.io/eds232-ml/lab4c_5.2.small-convnets.html).

1. **10 Species (multi-class classification) - neural net**.  Draw from [3.5 üì∞ Newswires (multi-class classification)](./lab4b_examples.html).

1. **10 Species (multi-class classification) - convolutional neural net**. Draw from [dogs vs cats example](https://bbest.github.io/eds232-ml/lab4c_5.2.small-convnets.html) and update necessary values to go from binary to multi-class classification.

In your models, be sure to include the following:

- Split the original images per species (n=50) into train (n=30), validate (n=10) and test (n=10). These are almost absurdly few files to feed into these complex deep learning models but will serve as a good learning example.

- Include accuracy metric and validation in the fitting process and history plot.

- Evaluate loss and accuracy on your test model results. Compare standard neural network and convolutional neural network results.
